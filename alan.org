#+begin_export latex
\section*{Implementation}
The program \ty{alan} has hooks for imports and main function.
#+end_export
#+begin_src go <<alan.go>>=
  package main
  import (
	  //<<Imports>>
  )
  func main() {
	  //<<Main function>>
  }
#+end_src
#+begin_export latex
In the main function, we declare the options, set the usage, parse the
options, prepare the subject, analyze queries, and print the results.
#+end_export
#+begin_src go <<Main function>>=
  //<<Declare options>>
  //<<Set usage>>
  //<<Parse options>>
  //<<Prepare the subject>>
  //<<Prepare for a homology search>>
  //<<Analyze queries>>
  //<<Print the results>>
#+end_src
#+begin_export latex
The program takes \ty{fasta}-formatted sequences as input. There is
one reference (subject), the rest of the files are considered
queries. The user can set thresholds for the minimum anchor length and
fraction of intersecting nucleotides.  We also declare options for the
output formatting, toggling the verbose mode and for printing the
version.
#+end_export
#+begin_src go <<Declare options>>=
  var optR = flag.String("r", "", "reference sequence")
  var optA = flag.Int("a", 0, "minimum anchor length")
  var optP = flag.Float64("p", 0.05,
	  "p-value for a non-random shustring")
  var optVerb = flag.Bool("verbose", false, "toggle verbose mode")
  var optN = flag.Bool("n", false, "print segregation sites (Ns)" +
	  "in the output sequences")
  var optS = flag.Bool("s", false, "print segregation site ranges" +
	  "to stderr")
  var optF = flag.Float64("f", 1.0, "intersection sensitivity threshold")
  var optV = flag.Bool("v", false, "print version and " +
	  "program information")
#+end_src
#+begin_export latex
We improt \ty{flag}.
#+end_export
#+begin_src go <<Imports>>=
  "flag"
#+end_src
#+begin_export latex
The usage consists of three statements. The actual usage statement, an
explanation of the programâ€™s purpose, and an example command.
#+end_export
#+begin_src go <<Set usage>>=
  u := "alan [option]..."
  p := "Find approximate local alignment"
  e := "alan -s subject.fasta -q query.fasta"
  clio.Usage(u, p, e)
#+end_src
#+begin_export latex
We import \ty{clio}.
#+end_export
#+begin_src go <<Imports>>=
  "github.com/evolbioinf/clio"
#+end_src
#+begin_export latex
We parse the options and respond to \ty{-v}. A proper response will
require the \ty{util} package, but for now, we leave a placeholder
here. The trailing arguments are interpreted as input file names.
#+end_export
#+begin_src go <<Parse options>>=
  flag.Parse()
  if *optV {
	  fmt.Println("alan v0.2")
  }
  fileNames := flag.Args()
#+end_src
#+begin_export latex
We import \ty{fmt}. We leave a placeholder to to import \ty{util}...
#+end_export
#+begin_src go <<Imports>>=
  "fmt"
  //"github.com/ivantsers/alan/util"
#+end_src
#+begin_export latex
We check the number of input files and if the subject was selected. If
so, we separate names of query sequences from the subject.
#+end_export
#+begin_src go <<Parse options>>=
  if len(fileNames) < 2 {
	  fmt.Fprintf(os.Stderr, "please specify at least two input files\n")
	  os.Exit(1)
  }
  queryNames := []string{}
  if *optR == "" {
	  fmt.Fprintf(os.Stderr, "please specify the reference sequence\n")
	  os.Exit(1)
  } else {
	  //<<Separate queries from the subject>>
  }
#+end_src
#+begin_export latex
We import \ty{os}.
#+end_export
#+begin_src go <<Imports>>=
  "os"
#+end_src
#+begin_export latex
We compare subject's names to query's to isolate the second.
#+end_export
#+begin_src go <<Separate queries from the subject>>=
  for _, fileName := range fileNames {
	  if fileName != *optR {
		  queryNames = append(queryNames, fileName)
	  }
  }
#+end_src
#+begin_export latex
We read the subject contigs and concatenate all entries into one
contig.  Thereafter, we clean the subject data from non-canonical
nucleotides and lowercase bytes (the latter are converted to
uppercase). Then deduce the reverse strand, and, finally, build an ESA
of the subject.
#+end_export
#+begin_src go <<Prepare the subject>>=
  f, _ := os.Open(*optR)
  subjectContigs := fasta.ReadAll(f)
  f.Close()
  subject := fasta.Concatenate(subjectContigs, 0)
  subject.Clean()
  //<<Get reverse strand>>
  se := esa.MakeEsa(subject.Data())
#+end_src
#+begin_export latex
We import \ty{fasta} and \ty{esa}.
#+end_export
#+begin_src go <<Imports>>=
  "github.com/ivantsers/fasta"
  "github.com/evolbioinf/esa"
#+end_src
#+begin_export latex
We get the reverese strand and append it to the forward strand.
#+end_export
#+begin_src go <<Get reverse strand>>=
  rev := fasta.NewSequence(subject.Header(), subject.Data())
  rev.ReverseComplement()
  subject.SetData(append(subject.Data(), rev.Data()...))
#+end_src
#+begin_export latex
We prepare for homology search. We calculate the length of the subject
(both strands), its GC content, and the minimum anchor length.
#+end_export
#+begin_src go <<Prepare for a homology search>>=
  sl := subject.Length()
  sgc := subject.GC()
  //<<Calculate minimum anchor length>>
#+end_src
#+begin_export latex
We check whether the user has specified the minimum anchor length. If
so, we use this value. If they haven't, we use a p-value, be it
provided by the user of the default one. We take the complement of the
p-value and use it as the threshold probability for
\ty{sus.Quantile()}. We print the minimum anchor length in the verbose
mode.
#+end_export
#+begin_src go <<Calculate minimum anchor length>>=
  var sma int
  if *optA > 0 {
	  sma = *optA
  } else {
	  sma = sus.Quantile(sl/2, sgc, 1.0 - *optP)
  }
  if *optVerb {
	  fmt.Fprintf(os.Stderr,
		  "# minimum anchor length: %d\n", sma)
  }
#+end_src
#+begin_export latex
We import \ty{sus}.
#+end_export
#+begin_src go <<Imports>>=
  "github.com/evolbioinf/sus"
#+end_src
#+begin_export latex
We calculate the number of queries and initialize a slice to store
non-overlapping homologous segments found in a query. Thereafter, we
iterate over all queries and search homologies. Upon completing the
search, we reduce \ty{allH} to an intersection with a given
sensitivity threshold.
#+end_export
#+begin_src go <<Analyze queries>>=
  numQueries := len(queryNames)
  allH := []ancs.Seg{}
  allNs := make(map[int]bool)
  for _, q := range queryNames {
	  //<<Prepare the query>>
	  //<<Conduct homology search>>
  }
  sensitivity := *optF
  //<<Intersect the homologies>>
#+end_src
#+begin_export latex
We import \ty{ancs}.
#+end_export
#+begin_src go <<Imports>>=
  "github.com/ivantsers/ancs"
#+end_src
#+begin_export latex
We read and concatenate the query, then we clean it.
#+end_export
#+begin_src go <<Prepare the query>>=
  f, _ = os.Open(q)
  queryContigs := fasta.ReadAll(f)
  f.Close()
  query := fasta.Concatenate(queryContigs, 0)
  query.Clean()
#+end_src
#+begin_export latex
Now that we have prepared the input, we conduct the homology search
and reduce the results to the longest chain of non-overlapping
homologies.
#+end_export
#+begin_src go <<Conduct homology search>>=
  h, ns := ancs.FindHomologies(query, subject, se,  sma)
  ancs.SortByStart(h)
  allH = append(allH, ancs.ReduceOverlaps(h)...)
  for pos, _ := range ns {
      allNs[pos] = true
  }
#+end_src
#+begin_export latex
We intersect the homologous segments.
#+end_export
#+begin_src go <<Intersect the homologies>>=
  intersection := ancs.Intersect(allH, numQueries, sensitivity, sl/2)
#+end_src
#+begin_export latex
If the verbose mode is toggled, we print the total number of the found
homologies. their total length, and number of segregation sites. If
\ty{-r} flag is called, we print segregation site coordinates and
their coordinates to \ty{stderr}. Then we proceed with printing
\ty{fasta}-formatted homologies to \ty{stdout}. Thus, the complete
output consists of:
\begin{itemize}
  \itemsep0em
\item \ty{stderr}: the search statistics, lines begin with an \ty{\#};
\item \ty{stderr}: coordinates of segregation sites;
  \item \ty{stdout}: \ty{fasta}-formatted homologies with or without
    segregation sites shown as \ty{Ns}.
\end{itemize}
#+end_export
#+begin_src go <<Print the results>>=
  if *optVerb {
	  fmt.Fprintf(os.Stderr,
		  "# %d homologous segments(s)\n", len(intersection))
	  fmt.Fprintf(os.Stderr,
		  "# total length: %d\n", ancs.TotalSegLen(intersection))
	  fmt.Fprintf(os.Stderr,
		  "# %d segregation site(s)\n", len(allNs))
      }
  if *optS {
	  ancs.PrintSegsiteRanges(allNs, intersection, os.Stderr)
  }
  result := ancs.SegToFasta(intersection, se, allNs, *optN)
  for _, seq := range(result) {
	  fmt.Fprintf(os.Stdout, "%s\n", seq)
  }
#+end_src
